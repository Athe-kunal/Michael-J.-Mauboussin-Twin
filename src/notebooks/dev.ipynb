{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://www.michaelmauboussin.com/writing\"\n",
    "\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"sqs-html-content\">\n",
      "<ul data-rte-list=\"default\"><li><pre><code><a href=\"https://mjbaldbard.files.wordpress.com/2020/09/michael-mauboussin-e28093-research-articles-and-interviews-1995-2004.pdf\">Research, Articles and Interviews (1995-2004)</a> </code></pre></li><li><pre><code><a href=\"https://mjbaldbard.files.wordpress.com/2020/09/michael-mauboussin-e28093-research-articles-and-interviews-2005-2011.pdf\">Research, Articles and Interviews (2005-2011)</a> </code></pre></li><li><pre><code><a href=\"https://mjbaldbard.files.wordpress.com/2020/09/michael-mauboussin-e28093-research-articles-and-interviews-2012-2013.pdf\">Research, Articles and Interviews (2012-2013)</a> </code></pre></li><li><pre><code><a href=\"https://mjbaldbard.files.wordpress.com/2020/09/michael-mauboussin-e28093-research-articles-and-interviews-2014.pdf\">Research, Articles and Interviews (2014)</a> </code></pre></li><li><pre><code><a href=\"https://mjbaldbard.files.wordpress.com/2020/09/michael-mauboussin-e28093-base-rate-books-2015-2016.pdf\">Base Rate Books (2015-2016)</a> </code></pre></li><li><pre><code><a href=\"https://mjbaldbard.files.wordpress.com/2020/09/michael-mauboussin-e28093-research-articles-and-interviews-2015-2016.pdf\">Research, Articles and Interviews (2015-2016) </a></code></pre></li><li><pre><code><a href=\"https://mjbaldbard.files.wordpress.com/2020/09/michael-mauboussin-e28093-research-articles-and-interviews-2016.pdf\">Research, Articles and Interviews (2016)</a> </code></pre></li><li><pre><code><a href=\"https://mjbaldbard.files.wordpress.com/2020/09/michael-mauboussin-e28093-research-articles-and-interviews-2017-2020-1.pdf\">Research, Articles and Interviews (2017-2020)</a> </code></pre></li><li><pre><code><a href=\"https://www.morganstanley.com/im/en-us/financial-advisor/insights/series/consilient-observer.html\">The Consilient Observer (2020 - present)</a> </code></pre><p class=\"sqsrte-small\" style=\"white-space:pre-wrap;\"><br/>*Thanks to <a href=\"https://mjbaldbard.Wordpress.com\">Mayur Jain</a> for assembling these materials (View him on <a href=\"https://twitter.com/mjbaldbard\">Twitter</a>)</p></li></ul><p class=\"\" data-rte-preserve-empty=\"true\" style=\"white-space:pre-wrap;\"></p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "data = soup.find_all(class_=\"sqs-html-content\")[-2]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.find_all('a')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Research, Articles and Interviews (2005-2011)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.find_all('a')[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.morganstanley.com/im/publication/insights/articles/article_chartsfromthevaultpicturestoponder.pdf?1736712102328\n",
    "# https://www.morganstanley.com/im/publication/insights/articles/article_measuringthemoat.pdf?1736712206119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col-md-8 col-sm-12 col-xs-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selenium.webdriver.chrome.webdriver.WebDriver"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.morganstanley.com/im/en-us/financial-advisor/insights/series/consilient-observer.html\"\n",
    "\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all article links\n",
    "articles = driver.find_elements(By.CSS_SELECTOR, \".series-detail-articles a\")\n",
    "\n",
    "# Create a set to track unique URLs\n",
    "seen_urls = set()\n",
    "\n",
    "for article in articles:\n",
    "    url = article.get_attribute('href')\n",
    "    # Only open if we haven't seen this URL before\n",
    "    if url not in seen_urls:\n",
    "        # Open in new tab using JavaScript since it handles dynamic content better\n",
    "        driver.execute_script(\"window.open(arguments[0], '_blank');\", url)\n",
    "        seen_urls.add(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to each tab and close it\n",
    "tabs = driver.window_handles\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.switch_to.window(driver.window_handles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'76B659795C15F8ECC93B148B2105F08A'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.window_handles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May 20, 2020\n",
      "Myth Busting, Popular Delusions, and the Variant Perception\n"
     ]
    }
   ],
   "source": [
    "DATE_CLASS = \"insightHeaderTextRegular text-uppercase customColor insightDateColor\"\n",
    "TITLE_CLASS = \"heroProductName equalSpace noMargin customColor\"\n",
    "\n",
    "print(soup.find(class_=DATE_CLASS).text.strip())\n",
    "print(soup.find(class_=TITLE_CLASS).text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We address four myths or popular delusions in the investment industry:\n",
      "\n",
      "Short-termism is rampant and deleterious: We hear this argument made a lot but often without concrete evidence, so we critically examine some of the claims to see if they hold up;\n",
      "Dividends play a large role in equity returns over time: We show that price appreciation is the only source of investment return that increases accumulated capital;\n",
      "Investing in money-losing companies is a bad idea: This is too simplistic, as some money-losing companies may still have attractive economics; and\n",
      "The rise of indexing has made it easier to be an active manager: If the investors who have turned to indexing tend to be less skillful, the remaining investors are left competing against stronger competition, making it harder to generate alpha.\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(class_=\"blockText\").text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_CLASS = \"buttoncomponent left custom-btn btn btn-default btn-lg\"\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "pdf_link = driver.find_element(By.CLASS_NAME, PDF_CLASS.replace(\" \", \".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.morganstanley.com/im/publication/insights/articles/article_mythbustingpopulardelusions_en.pdf?1736836675831'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_link.get_attribute(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[32mâ \u001b[0m Initializing ZenML repository at \n",
      "/Users/athekunal/Desktop/LLM-Engineering/Michael-J.-Mauboussin-Twin/src.\n",
      "\u001b[1;35mSetting the repo active workspace to 'default'.\u001b[0m\n",
      "\u001b[33mSetting the repo active stack to default.\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36mZenML repository initialized at \u001b[0m\n",
      "\u001b[2;35m/Users/athekunal/Desktop/LLM-Engineering/Michael-J.-Mauboussin-Twin/\u001b[0m\u001b[2;95msrc.\u001b[0m\n",
      "\u001b[2;32mâ \u001b[0m\u001b[2;36m Initializing ZenML repository at \u001b[0m\n",
      "\u001b[2;36m/Users/athekunal/Desktop/LLM-Engineering/Michael-J.-Mauboussin-Twin/src.\u001b[0m\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[32mâ \u001b[0m Initializing ZenML repository at \n",
      "/Users/athekunal/Desktop/LLM-Engineering/Michael-J.-Mauboussin-Twin/src.\n",
      "\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[2;36mThe local active stack was initialized to \u001b[0m\u001b[2;32m'default'\u001b[0m\u001b[2;36m. This local configuration \u001b[0m\n",
      "\u001b[2;36mwill only take effect when you're running ZenML from the initialized repository \u001b[0m\n",
      "\u001b[2;36mroot, or from a subdirectory. For more information on repositories and \u001b[0m\n",
      "\u001b[2;36mconfigurations, please visit \u001b[0m\n",
      "\u001b[2;4;94mhttps://docs.zenml.io/user-guide/production-guide/understand-stacks.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import zenml\n",
    "\n",
    "!zenml init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from michael_mauboussin_twin.feature.extract import extract_data\n",
    "\n",
    "# o = extract_data.extraction_data()\n",
    "# o[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATABASE\n",
    "\n",
    "Today's aim\n",
    "\n",
    "1. Test the vector store for vision model\n",
    "2. Docling for the text model\n",
    "3. Test the vector store for text model\n",
    "4. See how you can use Qdrant cloud to store the vector db\n",
    "5. PoC pipeline with text and vision model with streamlit and then proper UI/UX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDATING THE VISION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/recoverx/astarag/mj_project/Michael-J.-Mauboussin-Twin/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc6feafac664bb5898b7201d66fc64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a869ebd8253478b887e43de943d765c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmichael_mauboussin_twin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vision_db, settings\n\u001b[1;32m      3\u001b[0m vectors_config, quantization_config, optimizers_config \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mget_default_multi_vector_config(vector_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m vision_db_model \u001b[38;5;241m=\u001b[39m \u001b[43mvision_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVisionVectorStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVisionEmbeddingModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDBSettings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVISION_EMBEDDING_MODEL_PARAMS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVisionEmbeddingModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqdrant_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQdrantSettings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectors_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalar_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizers_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizers_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/astarag/mj_project/Michael-J.-Mauboussin-Twin/src/michael_mauboussin_twin/transform/base.py:159\u001b[0m, in \u001b[0;36mVectorStore.from_pretrained\u001b[0;34m(cls, model_config, config, qdrant_settings)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_pretrained\u001b[39m(\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mcls\u001b[39m: \u001b[38;5;28mtype\u001b[39m[T],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m     qdrant_settings: settings\u001b[38;5;241m.\u001b[39mQdrantSettings,\n\u001b[1;32m    152\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_config, settings\u001b[38;5;241m.\u001b[39mVisionEmbeddingModel):\n\u001b[1;32m    154\u001b[0m         model \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    155\u001b[0m             \u001b[43mcolpali_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mColQwen2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 159\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRAG_MODEL_DEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    161\u001b[0m         )\n\u001b[1;32m    162\u001b[0m         processor \u001b[38;5;241m=\u001b[39m colpali_model\u001b[38;5;241m.\u001b[39mColQwen2Processor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    163\u001b[0m             model_config\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    164\u001b[0m         )\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    167\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    168\u001b[0m             processor\u001b[38;5;241m=\u001b[39mprocessor,\n\u001b[1;32m    169\u001b[0m             db_settings\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    170\u001b[0m             qdrant_settings\u001b[38;5;241m=\u001b[39mqdrant_settings,\n\u001b[1;32m    171\u001b[0m         )\n",
      "File \u001b[0;32m~/astarag/mj_project/Michael-J.-Mauboussin-Twin/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:3157\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   3153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3156\u001b[0m         )\n\u001b[0;32m-> 3157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/astarag/mj_project/Michael-J.-Mauboussin-Twin/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/astarag/mj_project/Michael-J.-Mauboussin-Twin/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/astarag/mj_project/Michael-J.-Mauboussin-Twin/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/astarag/mj_project/Michael-J.-Mauboussin-Twin/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/astarag/mj_project/Michael-J.-Mauboussin-Twin/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/astarag/mj_project/Michael-J.-Mauboussin-Twin/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from michael_mauboussin_twin.transform import vision_db, settings\n",
    "\n",
    "vectors_config, quantization_config, optimizers_config = settings.get_default_multi_vector_config(vector_size=1024)\n",
    "vision_db_model = vision_db.VisionVectorStore.from_pretrained(\n",
    "    settings.VisionEmbeddingModel(),\n",
    "    settings.DBSettings(VISION_EMBEDDING_MODEL_PARAMS=settings.VisionEmbeddingModel()),\n",
    "    qdrant_settings=settings.QdrantSettings(vector_params=vectors_config, scalar_params=quantization_config, optimizers_config=optimizers_config),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_db_model.batch_encode_and_upsert_docs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
